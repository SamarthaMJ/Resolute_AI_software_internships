{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Basic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "\n",
    "xs =  np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=int)\n",
    "ys =  np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=int)\n",
    "\n",
    "\n",
    "model.compile(optimizer='sgd' , loss='mean_squared_error')\n",
    "model.fit(xs, ys , epochs=500)\n",
    "print(model.predict([5]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. MNSIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(training_labels[0])\n",
    "print(training_images[0])\n",
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=20)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Introduction to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "i = misc.ascent()\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.imshow(i)\n",
    "plt.show()\n",
    "\n",
    "i_trans = np.copy(i)\n",
    "xs = i_trans.shape[0]\n",
    "ys = i_trans.shape[1]\n",
    "\n",
    "filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "weight = 1\n",
    "for x in range(1,xs-1):\n",
    "  for y in range(1,ys-1):\n",
    "      output_pixel = 0.0\n",
    "      output_pixel = output_pixel + (i[x - 1, y-1] * filter[0][0])\n",
    "      output_pixel = output_pixel + (i[x, y-1] * filter[0][1])\n",
    "      output_pixel = output_pixel + (i[x + 1, y-1] * filter[0][2])\n",
    "      output_pixel = output_pixel + (i[x-1, y] * filter[1][0])\n",
    "      output_pixel = output_pixel + (i[x, y] * filter[1][1])\n",
    "      output_pixel = output_pixel + (i[x+1, y] * filter[1][2])\n",
    "      output_pixel = output_pixel + (i[x-1, y+1] * filter[2][0])\n",
    "      output_pixel = output_pixel + (i[x, y+1] * filter[2][1])\n",
    "      output_pixel = output_pixel + (i[x+1, y+1] * filter[2][2])\n",
    "      output_pixel = output_pixel * weight\n",
    "      if(output_pixel<0):\n",
    "        output_pixel=0\n",
    "      if(output_pixel>255):\n",
    "        output_pixel=255\n",
    "      i_trans[x, y] = output_pixel\n",
    "      \n",
    "# Plot the image. Note the size of the axes -- they are 512 by 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(i_trans)\n",
    "#plt.axis('off')\n",
    "plt.show()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Rock, paper, scissor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAINING_DIR = r\"C:\\Users\\sammj\\PycharmProjects\\rps_train\"\n",
    "training_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "\t    rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "VALIDATION_DIR = r\"C:\\Users\\sammj\\PycharmProjects\\rps_test\"\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "\tTRAINING_DIR,\n",
    "\ttarget_size=(150,150),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=10\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\tVALIDATION_DIR,\n",
    "\ttarget_size=(150,150),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=10\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)\n",
    "\n",
    "model.save(\"rps.h5\")\n",
    "\n",
    "#plot graph\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Intro and loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Video capture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('gray',gray)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "out=cv2.VideoWriter('output.avi',fourcc,20.0,(640,480))\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('gray',gray)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Drawing and Writing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.line(img,(0,0),(170,150),(255,255,255),15)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.line(img,(0,0),(150,150),(255,255,255),15)\n",
    "cv2.rectangle(img,(15,25),(200,150),(0,255,0),5)\n",
    "cv2.circle(img,(100,63),55,(0,0,255),-1)\n",
    "pts=np.array([[10,5],[20,30],[70,20],[50,10]],np.int32)\n",
    "#pts=pts.reshape((-1,1,2))\n",
    "cv2.polylines(img,[pts],True,(0,255,255),3)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Image operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch.jpg\", cv2.IMREAD_COLOR)\n",
    "px=img[55,55]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch.jpg\", cv2.IMREAD_COLOR)\n",
    "px=img[55,55]\n",
    "img[55,55]=[255,255,255]\n",
    "px=img[55,55]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch_2.jpg\", cv2.IMREAD_COLOR)\n",
    "img[55,55]=[255,255,255]\n",
    "px=img[55,55]\n",
    "img[100:150,100:150]=[0,0,0]\n",
    "watch_face=img[37:111,107:194]\n",
    "img[0:74,0:87]=watch_face\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch_2.jpg\", cv2.IMREAD_COLOR)\n",
    "img[55,55]=[255,255,255]\n",
    "px=img[55,55]\n",
    "img[100:150,100:150]=[0,0,0]\n",
    "watch_face=img[37:111,107:194]\n",
    "img[0:74,0:87]=watch_face\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Image arithmetics and logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img_1 = r\"C:\\Users\\sammj\\Downloads\\lion.jpg\"\n",
    "img_2 = r\"C:\\Users\\sammj\\Downloads\\cat.jpg\"\n",
    "# Load the first image\n",
    "image1 = cv2.imread(img_1)\n",
    "\n",
    "# Load the second image\n",
    "image2 = cv2.imread(img_2)\n",
    "\n",
    "# Add the images together\n",
    "result = cv2.add(image1, image2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Added Images', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch_2.jpg\")\n",
    "retval,threshold=cv2.threshold(img,12,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('threshold',threshold)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch_2.jpg\")\n",
    "retval,threshold=cv2.threshold(img,12,255,cv2.THRESH_BINARY)\n",
    "grayscaled=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "retval2,threshold2=cv2.threshold(grayscaled,12,255,cv2.THRESH_BINARY)\n",
    "gaus=cv2.adaptiveThreshold(grayscaled,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1)\n",
    "retval2,otsu=cv2.threshold(grayscaled,125,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('threshold',threshold)\n",
    "cv2.imshow('threshold2',threshold2)\n",
    "cv2.imshow('gaus',gaus)\n",
    "cv2.imshow('otsu',otsu)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Color filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([30,150,50])\n",
    "    upper_red = np.array([255,255,180])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Blurring and Smoothening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([30,150,50])\n",
    "    upper_red = np.array([255,255,180])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    kernel = np.ones((15,15),np.float32)/225\n",
    "    smoothed = cv2.filter2D(res,-1,kernel)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    #cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.imshow('smoothed',smoothed)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Morphological Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([30,150,50])\n",
    "    upper_red = np.array([255,255,180])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    erosion=cv2.erode(mask,kernel,iterations=1)\n",
    "    dilation=cv2.dilate(mask,kernel,iterations=1)\n",
    "    opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    cv2.imshow('res',res)\n",
    "    cv2.imshow('erosion',erosion)\n",
    "    cv2.imshow('dilation',dilation)\n",
    "    cv2.imshow('Opening',opening)\n",
    "    cv2.imshow('Closing',closing)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Canny edge deteection and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    _, frame = cap.read()\n",
    "    laplacion=cv2.Laplacian(frame,cv2.CV_64F)\n",
    "    sobelx = cv2.Sobel(frame,cv2.CV_64F,1,0,ksize=5)\n",
    "    sobely = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=5)\n",
    "    edges=cv2.Canny(frame,100,100)\n",
    "    cv2.imshow('original',frame)\n",
    "    cv2.imshow('laplacion',laplacion)\n",
    "    cv2.imshow('sobelx',sobelx)\n",
    "    cv2.imshow('sobely',sobely)\n",
    "    cv2.imshow('edges',edges)\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_bgr = cv2.imread(r\"C:\\Users\\sammj\\Downloads\\template_3\")\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread(r\"C:\\Users\\sammj\\Downloads\\template_2\", 0)\n",
    "w,h = template.shape[::-1]\n",
    "res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.7\n",
    "loc = np.where(res >= threshold)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow('Detected', img_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Grabcut Foreground Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\watch_2.jpg\")\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "\n",
    "rect = (50,100,180,400)\n",
    "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\corner.png\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray=np.float32(gray)\n",
    "corners=cv2.goodFeaturesToTrack(gray,50,0.01,10)\n",
    "corners=np.int0(corners)\n",
    "for corner in corners:\n",
    "    x,y=corner.ravel()\n",
    "    cv2.circle(img,(x,y),3,255,-1)\n",
    "cv2.imshow('Corner',img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\b1.png\",1)\n",
    "img2=cv2.imread(r\"C:\\Users\\sammj\\Downloads\\b2.png\",1)\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:10],None, flags=2)\n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. MOG Background Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture('C:\\\\Users\\\\sl876\\\\Downloads\\\\Random Nature Short Video__.mp4')\n",
    "fgbg=cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    fgmask=fgbg.apply(frame)\n",
    "    cv2.imshow('original',frame)\n",
    "    cv2.imshow('fg',fgmask)\n",
    "    k = cv2.waitKey(30) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Haar Cascade Object Detection Face & Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Own haar cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(r\"C:\\Users\\sammj\\PycharmProjects\\haarcascade_frontalface_alt.xml\")\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF==('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
